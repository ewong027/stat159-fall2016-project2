#Analysis
```{r, echo = FALSE, include = FALSE}
scaled_credit <- read.csv("../../data/datasets/scaled-credit.csv")

#Loading in the regression data to be used in the report.
load("../../data/RData-files/lasso-regression.RData")
load("../../data/RData-files/pls-regression.RData")

library(xtable)
library(png)
library(grid)
```
##Ordinary Least Squares Regression 

##Ridge Regression 

##Lasso Regression 
In lasso regression we found a $\lambda$ that capped the coefficients. The right lambda was chosen based off the MSE, the mean squared error. The *MSE Plot of Lasso Regression* plot shows the relationship between MSE and the log of lambda.  
```{r fig.width = 5, fig.height = 3, fig.align = "center", echo = FALSE, fig.cap = "MSE Plot of Lasso Regression"} 
img <- readPNG("../../images/cv-lasso-mse-plot.png")
grid.raster(img)
```
We use the $\lambda$ that gives the smallest MSE. This is given by the left-most value on this graph. We got this analysis from the training data set, which helped us fit the best model. 

In order to test the model, we used the testing data set. We fit the model using the $\lambda$ from above and calculated the MSE. This will test how acccurate of a fit the model is. When we did this, we got an MSE of `r lasso_mse`. 

Then using the full dataset, we came up the following coefficients in ((((table blah))))
Although we got the $\lambda$ from the training dataset, we got these coefficients from the entire dataset, `scaled-credit.csv`. Some of the coefficients have been set to zero by the lasso regression analysis. As mentioned earlier, lasso regression has a dimension reduction component and will only fit the data to the variables that fit the mse criteria. Our analysis shows six beta coefficients that have been set to zero. 

##Principal Components Regression

##Partial Least Squares Regression
In PLS regression, we have to find right M, which is the number of components to be used. This is chosen based off the MSE, the mean squared error. The *MSEP Plot of Partial Least Squares* plot shows the relationship between MSEP (mean squared error of predictions) and the number of components.

```{r fig.width = 5, fig.height = 3, fig.align = "center", echo = FALSE, fig.cap = "MSEP Plot of Partial Least Squares Regression"} 
img <- readPNG("../../images/cv-pls-mse-plot.png")
grid.raster(img)
```
We use the M that gives the smallest MSEP/MSE. We received this minimization from cross validation. We got this analysis from the training data set, which helped us fit the best model. 

In order to test the model, we used the testing data set. We fit the model using the M from above and calculated the MSE. This will test how acccurate of a fit the model is. When we did this, we got an MSE of `r pls_mse`. 

Then using the full dataset, we came up the ceofficients in ((((table blah))))
Although we got the M from the training dataset, we got these coefficients from the entire dataset, `scaled-credit.csv`. 

